{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f21dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "325cd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'E:\\AB\\breast_cancer\\train'\n",
    "img_h,img_w= (224,224)\n",
    "batch_size=256\n",
    "epochs=3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen= ImageDataGenerator(rescale=1./255,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb9ddfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_45 (Conv2D)          (None, 54, 54, 32)        11648     \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 54, 54, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 27, 27, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 17, 17, 64)        247872    \n",
      "                                                                 \n",
      " activation_80 (Activation)  (None, 17, 17, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " activation_82 (Activation)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 2, 2, 256)         295168    \n",
      "                                                                 \n",
      " activation_83 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 1, 1, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_85 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " activation_86 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 742,124\n",
      "Trainable params: 742,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "#from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 \n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.metrics import Metric\n",
    "base_model= ResNet50(include_top=False, weights='imagenet',\n",
    "                                       input_tensor=None, input_shape=(img_h,img_w,3), pooling='avg')\n",
    " \n",
    "for layer in base_model.layers[:-7]:\n",
    "    layer.trainable=False\n",
    "\n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "# MODEL HAS BEEN TAKEN FROM THE INTERNET\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=32, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(200, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Output Layer\n",
    "#model.add(Dense(10))\n",
    "#model.add(Activation('softmax'))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d5cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000001FC22DC90A0> --> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001FC2D88EC70> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2D93E040> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2D93EDF0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2D93E640> --> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001FC2D93E160> --> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001FC2DB07F40> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB3EA00> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB3EC10> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2D980640> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB4AFA0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB54A30> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB54670> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB38E50> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB4AEE0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB38490> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB5FDC0> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC2DB5FA00> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB4EBE0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB69EE0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB6D2E0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB6DD90> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB75FA0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB7FB50> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB7F790> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB75BB0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB89AF0> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC2DB5BD60> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB75FD0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB8FFD0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB953D0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB780A0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB9DFD0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DBA7C40> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DBA7880> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB9D2B0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33BE3FA0> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33BE3BE0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DBA73D0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB89E80> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB45E50> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB693D0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DBAFEE0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33BEE9A0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC2DB076A0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB9DD60> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33BEFEB0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC2DB69430> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33BEE310> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33BEBD60> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33BFAD90> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33BEEA30> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C01EB0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C07B80> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C07370> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33BFA280> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C07E50> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C0F910> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C1E160> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33C15790> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C269A0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C1EBE0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C32190> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C32BB0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C1E6D0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C3F250> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C0F8B0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C43AC0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C49A30> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33C26340> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C52F40> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C49B20> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C5EA30> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C5E610> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C622B0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C6CAC0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C70790> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C6CD30> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C52DF0> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33C703A0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C2D7C0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC2DB861F0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C372E0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C49BB0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C76D90> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C7A220> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C7B040> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C43760> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C7BB50> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C0F610> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C7E700> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33C813D0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C81DF0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C7EF40> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C8D700> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C7B460> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C91550> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C98790> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C91C70> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C85C40> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CA4C70> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33C9ECA0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CAAAF0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CA4790> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CB8C70> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CBCBB0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CB8EB0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CA4D00> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CC9A30> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CC26D0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CCFF40> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33CDB040> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CDB970> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CD44C0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CE2F40> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CE99A0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CE2160> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CCF250> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CE2310> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CA40D0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C850D0> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC2DB75BE0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CC9D60> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C7B4F0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CED9A0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C62C40> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33C791C0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CF3820> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CEDA00> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CF4D60> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CF6D00> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33CF1F40> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33CF4D30> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CF6DC0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D04D00> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D0A9D0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D04D90> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33CF6E20> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D15A60> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D10250> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D242E0> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33D28130> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D289D0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D35A60> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D24580> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D35760> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D48C10> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D4D070> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D530D0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D244F0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D53D30> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D352E0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D5C8E0> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33D67760> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D67AF0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D615B0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D484C0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D41C40> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D48310> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D1D280> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D046D0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CFF700> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33C7E850> --> False\n",
      "<keras.layers.merge.Add object at 0x000001FC33CF6130> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33C9EC10> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33D6B220> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D6CDF0> --> False\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D282E0> --> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CA4EE0> --> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D6B850> --> True\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D6E0D0> --> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001FC33CA4940> --> True\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001FC33D7C100> --> True\n",
      "<keras.layers.merge.Add object at 0x000001FC33D72D30> --> True\n",
      "<keras.layers.core.activation.Activation object at 0x000001FC33D6C220> --> True\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x000001FC33D7CB20> --> True\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer,\"-->\",layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fa56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n",
    "                                         factor=0.1,\n",
    "                                         patience=3,\n",
    "                                         cooldown=2,\n",
    "                                         min_lr=1e-10,\n",
    "                                         verbose=1)\n",
    "\n",
    "checkpoint =tf.keras.callbacks.ModelCheckpoint(filepath=\"alexnet.h5\", \n",
    "                            monitor='val_accuracy',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True, \n",
    "                            save_weights_only=False, \n",
    "                            mode='auto',\n",
    "                            save_freq='epoch')\n",
    "\n",
    "\n",
    "import time\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "callbacks = [reduce_learning_rate, checkpoint, time_callback]\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#model.compile( loss='categorical_crossentropy',optimizer= optimizer, metrics=['accuracy',keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cadf7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3354 images belonging to 2 classes.\n",
      "Found 207 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_dir = r'E:\\AB\\breast_cancer\\val'\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        base_dir,  # This is the source directory for training images\n",
    "        target_size=(img_h,img_w),  \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        #color_mode=\"rgb\",\n",
    "        shuffle=True)\n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "         val_dir,     \n",
    "        target_size=(img_h, img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        #color_mode=\"rgb\",\n",
    "        subset='validation',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7849828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.6898 - precision_8: 0.6851 - recall_8: 0.6511WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "13/13 [==============================] - 51s 4s/step - loss: 0.6461 - accuracy: 0.6898 - precision_8: 0.6851 - recall_8: 0.6511 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples//batch_size, \n",
    "      epochs=25,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples//batch_size,  \n",
    "      callbacks=callbacks,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(validation_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dce7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'precision_6', 'recall_6', 'accuracy', 'lr'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b773a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 at epoch number- 1\n"
     ]
    }
   ],
   "source": [
    "accu= history.history['accuracy']\n",
    "print(max(accu),\"at epoch number-\",accu.index(max(accu))+1)\n",
    "\n",
    "\n",
    "#print(f\" — val_f1: {_val_f1} — val_precision: {_val_precision} — val_recall _val_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96fc1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"E:\\\\AB\\\\breast_cancer\\\\test\\\\opacity\\\\person16_virus_47.jpeg\") \n",
    "image_resized= cv2.resize(img, (img_h,img_w))\n",
    "'''cv2.imshow('CT scan', img)\n",
    "cv2.waitKey(0)'''\n",
    "img=np.expand_dims(image_resized,axis=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "pred=model.predict(img)\n",
    "#print(pred);\n",
    "yn=np.argmax(pred,axis=1)\n",
    "if yn==0:\n",
    "    print(\"Breast cancer\")\n",
    "else :\n",
    "    print(\"Not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f80be7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not pneumonia\n"
     ]
    }
   ],
   "source": [
    "yn=np.argmax(pred,axis=1)\n",
    "classes = []\n",
    "for subdir in sorted(os.listdir(base_dir)):\n",
    "    if os.path.isdir(os.path.join(base_dir, subdir)):\n",
    "        classes.append(subdir)\n",
    "if yn==0:\n",
    "    print(\"Breast cancer\")\n",
    "else :\n",
    "    print(\"Benign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11ee463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yn=np.argmax(pred,axis=1)\n",
    "classes = []\n",
    "for subdir in sorted(os.listdir(base_dir)):\n",
    "    if os.path.isdir(os.path.join(base_dir, subdir)):\n",
    "        classes.append(subdir)\n",
    "yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6420417b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_proba = model.predict(img)\n",
    "y_classes = y_proba.argmax(axis=-1)\n",
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60b03a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken is  6.0  minutes and  15.173778057098389  seconds\n"
     ]
    }
   ],
   "source": [
    "timings= time_callback.times\n",
    "n=sum(timings)\n",
    "print(\"Total time taken is \",sum(timings)//60,\" minutes and \",sum(timings)%60,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a7824f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 24s 24s/step\n",
      "0.2560386473429952\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9204/2802216000.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdf_cm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "model2= tf.keras.models.load_model(\"resfinal.h5\")\n",
    "y_pred= model2.predict(validation_generator,verbose=1)\n",
    "y_true= validation_generator.classes\n",
    "y_pred2= np.argmax(y_pred,axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_true,y_pred2))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf=confusion_matrix(yn, pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cf, range(2), range(2))\n",
    "df_cm.to_csv('ResNet50 prj'+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "249c9074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 53,   0],\n",
       "       [154,   0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c0445e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.86442685127258"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = max(accu)\n",
    "ac=ac*100\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d27d355d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9204/1278341330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1465\u001b[0m                                     pos_label)\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1275\u001b[0m                          str(average_options))\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(yn, pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060a7b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
